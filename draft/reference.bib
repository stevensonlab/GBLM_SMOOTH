@misc{,
title = {{Synapse - Wikipedia}},
url = {https://en.wikipedia.org/wiki/Synapse},
urldate = {2020-11-28}
}
@article{Abbott1997,
author = {Abbott, L F and Varela, J A and Sen, K and Nelson, S B},
journal = {Science},
number = {5297},
pages = {221},
title = {{Synaptic depression and cortical gain control}},
volume = {275},
year = {1997}
}
@article{Amarasingham2015,
abstract = {Among the most important open questions in neurophysiology are those regarding the nature of the code that neurons use to transmit information. Experimental approaches to such questions are challenging because the spike outputs of a neuronal subpopulation are influenced by a vast array of factors, ranging from microscopic to macroscopic scales, but only a small fraction of these is measured. Inevitably, there is variability from trial to trial in the recorded data. We show that a prominent conceptual approach to modeling spike-train variability can be ill-posed, confusing the interpretation of results bearing on neural codes. We argue for more careful definitions and more explicit statements of physiological assumptions.},
author = {Amarasingham, Asohan and Geman, Stuart and Harrison, Matthew T.},
doi = {10.1073/PNAS.1506400112},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {may},
number = {20},
pages = {6455--6460},
pmid = {25934918},
publisher = {National Academy of Sciences},
title = {{Ambiguity and nonidentifiability in the statistical analysis of neural codes}},
url = {https://www.pnas.org/content/112/20/6455},
volume = {112},
year = {2015}
}
@article{Ananthasayanam2016,
abstract = {Since the innovation of the ubiquitous Kalman filter more than five decades back it is well known that to obtain the best possible estimates the tuning of its statistics {\$}{\$}{\{}$\backslash$mathbf{\{}X{\}}{\}}{\_}{\{}$\backslash$mathbf{\{}0{\}}{\}}{\$}{\$}X0, {\$}{\$}{\{}$\backslash$mathbf{\{}P{\}}{\}}{\_}{\{}$\backslash$mathbf{\{}0{\}}{\}}{\$}{\$}P0, {\$}{\$}$\backslash$Theta {\$}{\$}$\Theta$, R and Q namely initial state and covariance, unknown parameters, and the measurement and state noise covariances is very crucial. The manual and other approaches have not matured to a routine approach applicable for any general problem. The present reference recursive recipe (RRR) utilizes the prior, posterior, and smoothed state estimates as well as their covariances to balance the state and measurement equations and thus form generalized cost functions. The filter covariance at the end of each pass is heuristically scaled up by the number of data points and further trimmed to provide the {\$}{\$}{\{}$\backslash$mathbf{\{}P{\}}{\}}{\_}{\{}$\backslash$mathbf{\{}0{\}}{\}}{\$}{\$}P0for subsequent passes. The importance of {\$}{\$}{\{}$\backslash$mathbf{\{}P{\}}{\}}{\_}{\{}$\backslash$mathbf{\{}0{\}}{\}}{\$}{\$}P0as the probability matching prior between the frequentist approach via optimization and the Bayesian approach of the Kalman filter is stressed. A simultaneous and proper choice for Q and R based on the filter sample statistics and other covariances leads to a stable filter operation after a few iterations. A typical simulation study of a spring, mass and damper system with a weak nonlinear spring constant by RRR shows it to be better than earlier techniques. Part-2 of the paper further consolidates the present approach based on an analysis of real flight test data.},
author = {Ananthasayanam, M R and Mohan, M Shyam and Naik, Naren and Gemson, R M O},
doi = {10.1007/s12046-016-0562-z},
issn = {0973-7677},
journal = {Sādhanā},
number = {12},
pages = {1473--1490},
title = {{A heuristic reference recursive recipe for adaptively tuning the Kalman filter statistics part-1: formulation and simulation studies}},
url = {https://doi.org/10.1007/s12046-016-0562-z},
volume = {41},
year = {2016}
}
@article{Bartho2004,
abstract = {Most neuronal interactions in the cortex occur within local circuits. Because principal cells and GABAergic interneurons contribute differently to cortical operations, their experimental identification and separation is of utmost important. We used 64-site two-dimensional silicon probes for high-density recording of local neurons in layer 5 of the somatosensory and prefrontal cortices of the rat. Multiple-site monitoring of units allowed for the determination of their two-dimensional spatial position in the brain. Of the ∼60,000 cell pairs recorded, 0.2{\%} showed robust short-term interactions. Units with significant, short-latency ({\textless}3 ms) peaks following their action potentials in their cross-correlograms were characterized as putative excitatory (pyramidal) cells. Units with significant suppression of spiking of their partners were regarded as putative GABAergic interneurons. A portion of the putative interneurons was reciprocally connected with pyramidal cells. Neurons physiologically identified as inhibitory and excitatory cells were used as templates for classification of all recorded neurons. Of the several parameters tested, the duration of the unfiltered (1 Hz to 5 kHz) spike provided the most reliable clustering of the population. High-density parallel recordings of neuronal activity, determination of their physical location and their classification into pyramidal and interneuron classes provide the necessary tools for local circuit analysis.},
author = {Barth{\'{o}}, Peter and Hirase, Hajime and Monconduit, Lena{\"{i}}c and Zugaro, Michael and Harris, Kenneth D. and Buzs{\'{a}}ki, Gy{\"{o}}rgy},
doi = {10.1152/jn.01170.2003},
issn = {00223077},
journal = {Journal of Neurophysiology},
month = {jul},
number = {1},
pages = {600--608},
pmid = {15056678},
publisher = {American Physiological Society},
title = {{Characterization of neocortical principal cells and interneurons by network interactions and extracellular features}},
url = {http://www.engin.umich.},
volume = {92},
year = {2004}
}
@article{Brillinger1988,
author = {Brillinger, D R},
journal = {Biological Cybernetics},
number = {3},
pages = {189--200},
title = {{Maximum likelihood analysis of spike trains of interacting nerve cells}},
volume = {59},
year = {1988}
}
@article{Brillinger1992,
abstract = {collections of occurences times of events taking place irregularly in time provide a fairly common, but not broadly discussed, data type. this artivle is concerned with the particular circumstance of firing times in nerve cells that interact and form networks. the artivle reviews a a progression of statistical analysis techniques, description, association as measured by moments and correlation, regression and finally likelihood. the data is point process, but may seen as that of regression of multivariate analysis in standard parlance. a simple description of data collected simulaneously for one or more cells is provided},
author = {Brillinger, David R.},
doi = {10.2307/2290256},
issn = {01621459},
journal = {Journal of the American Statistical Association},
title = {{Nerve Cell Spike Train Data Analysis: A Progression of Technique}},
year = {1992}
}
@article{Brown2001,
abstract = {Neural receptive fields are plastic: with experience, neurons in many brain regions change their spiking responses to relevant stimuli. Analysis of receptive field plasticity from experimental measurements is crucial for understanding how neural systems adapt their representations of relevant biological information. Current analysis methods using histogram estimates of spike rate functions in nonoverlapping temporal windows do not track the evolution of receptive field plasticity on a fine time scale. Adaptive signal processing is an established engineering paradigm for estimating time-varying system parameters from experimental measurements. We present an adaptive filter algorithm for tracking neural receptive field plasticity based on point process models of spike train activity. We derive an instantaneous steepest descent algorithm by using as the criterion function the instantaneous log likelihood of a point process spike train model. We apply the point process adaptive filter algorithm in a study of spatial (place) receptive field properties of simulated and actual spike train data from rat CA1 hippocampal neurons. A stability analysis of the algorithm is sketched in the [Appendix][1]. The adaptive algorithm can update the place field parameter estimates on a millisecond time scale. It reliably tracked the migration, changes in scale, and changes in maximum firing rate characteristic of hippocampal place fields in a rat running on a linear track. Point process adaptive filtering offers an analytic method for studying the dynamics of neural receptive fields.

 [1]: {\#}app-1},
author = {Brown, Emery N. and Nguyen, David P. and Frank, Loren M. and Wilson, Matthew A. and Solo, Victor},
doi = {10.1073/PNAS.201409398},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {oct},
number = {21},
pages = {12261--12266},
pmid = {11593043},
publisher = {National Academy of Sciences},
title = {{An analysis of neural receptive field plasticity by point process adaptive filtering}},
url = {https://www.pnas.org/content/98/21/12261},
volume = {98},
year = {2001}
}
@article{Carandini2007,
abstract = {At many synapses in the central nervous system, spikes within high-frequency trains have a better chance of driving the postsynaptic neuron than spikes occurring in isolation. We asked what mechanism accounts for this selectivity at the retinogeniculate synapse. The amplitude of synaptic potentials was remarkably constant, ruling out a major role for presynaptic mechanisms such as synaptic facilitation. Instead, geniculate spike trains could be predicted from retinal spike trains on the basis of postsynaptic summation. This simple form of integration explains the response differences between a geniculate neuron and its main retinal driver, and thereby determines the flow of visual information to cortex. {\textcopyright} ARVO.},
author = {Carandini, Matteo and Horton, Jonathan C. and Sincich, Lawrence C.},
doi = {10.1167/7.14.20},
issn = {15347362},
journal = {Journal of Vision},
keywords = {Natural statistics,Neural modeling,Receptive field,Retinal ganglion cell,Spike threshold,Temporal frequency},
month = {dec},
number = {14},
pages = {20--20},
pmid = {18217815},
publisher = {The Association for Research in Vision and Ophthalmology},
title = {{Thalamic filtering of retinal spike trains by postsynaptic summation}},
url = {http://journalofvision.org/7/14/20/,},
volume = {7},
year = {2007}
}
@inproceedings{Chan2008,
abstract = {Hippocampus and other parts of the cortex are not stationary, but change as a function of time and experience. The goal of this study is to apply adaptive modeling techniques to the tracking of multiple-input, multiple-output (MIMO) nonlinear dynamics underlying spike train transformations across brain subregions, e.g. CA3 and CA1 of the hippocampus. A stochastic state point process adaptive filter will be used to track the temporal evolutions of both feedforward and feedback kernels in the natural flow of multiple behavioral events.},
author = {Chan, Rosa H M and Song, Dong and Berger, Theodore W},
booktitle = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
doi = {10.1109/IEMBS.2008.4650336},
isbn = {978-1-4244-1814-5},
issn = {1557-170X},
pages = {4996--4999},
pmid = {19163839},
title = {{Tracking temporal evolution of nonlinear dynamics in hippocampus using time-varying volterra kernels.}},
volume = {2008},
year = {2008}
}
@article{10.3389/fncom.2013.00075,
abstract = {Short-term synaptic plasticity is highly diverse across brain area, cortical layer, cell type, and developmental stage. Since short-term plasticity (STP) strongly shapes neural dynamics, this diversity suggests a specific and essential role in neural information processing. Therefore, a correct characterization of short-term synaptic plasticity is an important step towards understanding and modeling neural systems. Phenomenological models have been developed, but they are usually fitted to experimental data using least-mean-square methods. We demonstrate that for typical synaptic dynamics such fitting may give unreliable results. As a solution, we introduce a Bayesian formulation, which yields the posterior distribution over the model parameters given the data. First, we show that common STP protocols yield broad distributions over some model parameters. Using our result we propose a experimental protocol to more accurately determine synaptic dynamics parameters. Next, we infer the model parameters using experimental data from three different neocortical excitatory connection types. This reveals connection-specific distributions, which we use to classify synaptic dynamics. Our approach to demarcate connection-specific synaptic dynamics is an important improvement on the state of the art and reveals novel features from existing data.},
author = {Costa, Rui and Sjostrom, P Jesper and van Rossum, Mark},
doi = {10.3389/fncom.2013.00075},
issn = {1662-5188},
journal = {Frontiers in Computational Neuroscience},
pages = {75},
title = {{Probabilistic inference of short-term synaptic plasticity in neocortical microcircuits}},
url = {https://www.frontiersin.org/article/10.3389/fncom.2013.00075},
volume = {7},
year = {2013}
}
@article{Csicsvari1998,
abstract = {Spike transmission probability between pyramidal cells and interneurons in the CA1 pyramidal layer was investigated in the behaving rat by the simultaneous recording of neuronal ensembles. Population synchrony was strongest during sharp wave (SPW) bursts. However, the increase was three times larger for pyramidal cells than for interneurons. The contribution of single pyramidal cells to the discharge of interneurons was often large (up to 0.6 probability), as assessed by the presence of significant ({\textless}3 ms) peaks in the cross-correlogram. Complex-spike bursts were more effective than single spikes. Single cell contribution was higher between SPW bursts than during SPWs or theta activity. Hence, single pyramidal cells can reliably discharge interneurons, and the probability of spike transmission is behavior dependent.},
author = {Csicsvari, Jozsef and Hirase, Hajime and Czurko, Andras and Buzs{\'{a}}ki, Gy{\"{o}}rgy},
doi = {10.1016/S0896-6273(00)80525-5},
issn = {08966273},
journal = {Neuron},
month = {jul},
number = {1},
pages = {179--189},
pmid = {9697862},
publisher = {Cell Press},
title = {{Reliability and state dependence of pyramidal cell-interneuron synapses in the hippocampus: An ensemble approach in the behaving rat}},
volume = {21},
year = {1998}
}
@article{10.1371/journal.pcbi.1008265,
abstract = {Author summary Synaptic long-term plasticity, the long-lasting change in efficacy of connections between neurons, is believed to underlie learning and memory. Synapses furthermore change their efficacy reversibly in an activity-dependent manner on the subsecond time scale, referred to as short-term plasticity. It is not known how both synaptic plasticity mechanisms—long- and short-term—interact during activity epochs. To address this question, we used a biologically-inspired plasticity model in which calcium drives changes in synaptic efficacy. We applied the model to plasticity data from visual- and somatosensory cortex and found that synaptic changes occur in very different firing rate ranges, which correspond to the prevalent firing rates in both structures. Our results suggest that short- and long-term plasticity act in a well concerted fashion.},
author = {Deperrois, Nicolas and Graupner, Michael},
doi = {10.1371/journal.pcbi.1008265},
journal = {PLOS Computational Biology},
number = {9},
pages = {1--25},
publisher = {Public Library of Science},
title = {{Short-term depression and long-term plasticity together tune sensitive range of synaptic plasticity}},
url = {https://doi.org/10.1371/journal.pcbi.1008265},
volume = {16},
year = {2020}
}
@article{Du2020,
abstract = {We discuss the R package SQUAREM for accelerating iterative algorithms which exhibit slow, monotone convergence. These include the well-known expectation-maximization algorithm, majorize-minimize (MM), and other EM-like algorithms such as expectation conditional maximization, and generalized EM algorithms. We demonstrate the simplicity, generality, and power of SQUAREM through a wide array of applications of EM/MM problems, including binary Poisson mixture, factor analysis, interval censoring, genetics admixture, and logistic regression maximum likelihood estimation (an MM problem). We show that SQUAREM is easy to apply, and can accelerate any fixed-point, smooth, contraction mapping with linear convergence rate. The squared iterative scheme (SQUAREM) algorithm provides significant speed-up of EM-like algorithms. The margin of the advantage for SQUAREM is especially huge for high-dimensional problems or when the EM step is relatively time-consuming to evaluate. SQUAREM can be used off-the-shelf since there is no need for the user to tweak any control parameters to optimize performance. Given its remarkable ease of use, SQUAREM may be considered as a default accelerator for slowly converging EM-like algorithms. All the comparisons of CPU computing time in the paper are made on a quad-core 2.3 GHz Intel Core i7 Mac computer. R package SQUAREM is available from the Comprehensive R Archive Network (CRAN) at https://CRAN.R-project.org/package=SQUAREM/.},
author = {Du, Yu and Varadhan, Ravi},
doi = {10.18637/jss.v092.i07},
journal = {Journal of Statistical Software; Vol 1, Issue 7 (2020)  },
keywords = {EM algorithm; fixed-point iteration; monotone conv},
title = {{SQUAREM: An R Package for Off-the-Shelf Acceleration of EM, MM and Other EM-Like Monotone Algorithms}},
url = {https://www.jstatsoft.org/v092/i07},
year = {2020}
}
@article{Eden2004,
abstract = {Neural receptive fields are dynamic in that with experience, neurons change their spiking responses to relevant stimuli. To understand how neural systems adapt the irrepresentations of biological information, analyses of receptive field plasticity from experimental measurements are crucial. Adaptive signal processing, the well-established engineering discipline for characterizing the temporal evolution of system parameters, suggests a framework for studying the plasticity of receptive fields. We use the Bayes' rule Chapman-Kolmogorov paradigm with a linear state equation and point process observation models to derive adaptive filters appropriate for estimation from neural spike trains. We derive point process filter analogues of the Kalman filter, recursive least squares, and steepest-descent algorithms and describe the properties of these new fil-ters. We illustrate our algorithms in two simulated data examples. The first is a study of slow and rapid evolution of spatial receptive fields in hippocampal neurons. The second is an adaptive decoding study in which a signal is decoded from ensemble neural spiking activity as the recep-tive fields of the neurons in the ensemble evolve. Our results provide a paradigm for adaptive estimation for point process observations and suggest a practical approach for constructing filtering algorithms to track neural receptive field dynamics on a millisecond timescale.},
annote = {doi: 10.1162/089976604773135069},
author = {Eden, Uri T and Frank, Loren M and Barbieri, Riccardo and Solo, Victor and Brown, Emery N},
doi = {10.1162/089976604773135069},
issn = {0899-7667},
journal = {Neural Computation},
month = {may},
number = {5},
pages = {971--998},
publisher = {MIT Press},
title = {{Dynamic Analysis of Neural Encoding by Point Process Adaptive Filtering}},
url = {https://doi.org/10.1162/089976604773135069},
volume = {16},
year = {2004}
}
@article{English2017,
abstract = {Excitatory control of inhibitory neurons is poorly understood due to the difficulty of studying synaptic connectivity in vivo. We inferred such connectivity through analysis of spike timing and validated this inference using juxtacellular and optogenetic control of presynaptic spikes in behaving mice. We observed that neighboring CA1 neurons had stronger connections and that superficial pyramidal cells projected more to deep interneurons. Connection probability and strength were skewed, with a minority of highly connected hubs. Divergent presynaptic connections led to synchrony between interneurons. Synchrony of convergent presynaptic inputs boosted postsynaptic drive. Presynaptic firing frequency was read out by postsynaptic neurons through short-term depression and facilitation, with individual pyramidal cells and interneurons displaying a diversity of spike transmission filters. Additionally, spike transmission was strongly modulated by prior spike timing of the postsynaptic cell. These results bridge anatomical structure with physiological function. English, McKenzie, et al. identify, validate, and quantify monosynaptic connections between pyramidal cells and interneurons, using the spike timing of pre- and postsynaptic neurons in vivo. Their large-scale method uncovers a backbone of connectivity rules in the hippocampus CA1 circuit.},
author = {English, Daniel Fine and McKenzie, Sam and Evans, Talfan and Kim, Kanghwan and Yoon, Euisik and Buzs{\'{a}}ki, Gy{\"{o}}rgy},
doi = {10.1016/j.neuron.2017.09.033},
issn = {10974199},
journal = {Neuron},
keywords = {cell assemblies,circuits,cooperativity,hippocampus,interneuron,lognormal,pyramidal cell,short-term plasticity,spike transmission,synchrony},
month = {oct},
number = {2},
pages = {505--520.e7},
pmid = {29024669},
publisher = {Cell Press},
title = {{Pyramidal Cell-Interneuron Circuit Architecture and Dynamics in Hippocampal Networks}},
volume = {96},
year = {2017}
}
@incollection{Fetz1991,
author = {Fetz, Eberhard and Toyama, Keisuke and Smith, Wade},
doi = {10.1007/978-1-4615-6622-9_1},
pages = {1--47},
publisher = {Springer, Boston, MA},
title = {{Synaptic Interactions between Cortical Neurons}},
url = {https://link.springer.com/chapter/10.1007/978-1-4615-6622-9{\_}1},
year = {1991}
}
@article{Fujisawa2008,
abstract = {Fujisawa and colleagues report that during a working memory task, firing patterns in ensembles of rat medial prefrontal cortex neurons reflect behavioral outcomes on coarser time scales and short-term synaptic plasticity on finer time scales. These results suggest that short-term plasticity plays a role in the neural computations guiding behavior.},
author = {Fujisawa, Shigeyoshi and Amarasingham, Asohan and Harrison, Matthew T and Buzs{\'{a}}ki, Gy{\"{o}}rgy},
doi = {10.1038/nn.2134},
issn = {1546-1726},
journal = {Nature Neuroscience},
number = {7},
pages = {823--833},
title = {{Behavior-dependent short-term assembly dynamics in the medial prefrontal cortex}},
url = {https://doi.org/10.1038/nn.2134},
volume = {11},
year = {2008}
}
@article{Ghanbari2017,
author = {Ghanbari, Abed and Malyshev, Aleksey and Volgushev, Maxim and Stevenson, Ian H.},
doi = {10.1371/journal.pcbi.1005738},
issn = {1553-7358},
journal = {PLOS Computational Biology},
month = {sep},
number = {9},
pages = {e1005738},
publisher = {Public Library of Science},
title = {{Estimating short-term synaptic plasticity from pre- and postsynaptic spiking}},
volume = {13},
year = {2017}
}
@article{Ghanbari4185,
abstract = {Information transmission in neural networks is influenced by both short-term synaptic plasticity (STP) as well as nonsynaptic factors, such as after-hyperpolarization currents and changes in excitability. Although these effects have been widely characterized in vitro using intracellular recordings, how they interact in vivo is unclear. Here, we develop a statistical model of the short-term dynamics of spike transmission that aims to disentangle the contributions of synaptic and nonsynaptic effects based only on observed presynaptic and postsynaptic spiking. The model includes a dynamic functional connection with short-term plasticity as well as effects due to the recent history of postsynaptic spiking and slow changes in postsynaptic excitability. Using paired spike recordings, we find that the model accurately describes the short-term dynamics of in vivo spike transmission at a diverse set of identified and putative excitatory synapses, including a pair of connected neurons within thalamus in mouse, a thalamocortical connection in a female rabbit, and an auditory brainstem synapse in a female gerbil. We illustrate the utility of this modeling approach by showing how the spike transmission patterns captured by the model may be sufficient to account for stimulus-dependent differences in spike transmission in the auditory brainstem (endbulb of Held). Finally, we apply this model to large-scale multielectrode recordings to illustrate how such an approach has the potential to reveal cell type-specific differences in spike transmission in vivo. Although STP parameters estimated from ongoing presynaptic and postsynaptic spiking are highly uncertain, our results are partially consistent with previous intracellular observations in these synapses.SIGNIFICANCE STATEMENT Although synaptic dynamics have been extensively studied and modeled using intracellular recordings of postsynaptic currents and potentials, inferring synaptic effects from extracellular spiking is challenging. Whether or not a synaptic current contributes to postsynaptic spiking depends not only on the amplitude of the current, but also on many other factors, including the activity of other, typically unobserved, synapses, the overall excitability of the postsynaptic neuron, and how recently the postsynaptic neuron has spiked. Here, we developed a model that, using only observations of presynaptic and postsynaptic spiking, aims to describe the dynamics of in vivo spike transmission by modeling both short-term synaptic plasticity (STP) and nonsynaptic effects. This approach may provide a novel description of fast, structured changes in spike transmission.},
author = {Ghanbari, Abed and Ren, Naixin and Keine, Christian and Stoelzel, Carl and Englitz, Bernhard and Swadlow, Harvey A and Stevenson, Ian H},
doi = {10.1523/JNEUROSCI.1482-19.2020},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {21},
pages = {4185--4202},
publisher = {Society for Neuroscience},
title = {{Modeling the Short-Term Dynamics of in Vivo Excitatory Spike Transmission}},
url = {https://www.jneurosci.org/content/40/21/4185},
volume = {40},
year = {2020}
}
@article{Graupner2012,
abstract = {Multiple stimulation protocols have been found to be effective in changing synaptic efficacy by inducing long-term potentiation or depression. In many of those protocols, increases in postsynaptic calcium concentration have been shown to play a crucial role. However, it is still unclear whether and how the dynamics of the postsynaptic calcium alone determine the outcome of synaptic plasticity. Here, we propose a calcium-based model of a synapse in which potentiation and depression are activated above calcium thresholds. We show that this model gives rise to a large diversity of spike timing-dependent plasticity curves, most of which have been observed experimentally in different systems. It accounts quantitatively for plasticity outcomes evoked by protocols involving patterns with variable spike timing and firing rate in hippocampus and neocortex. Furthermore, it allows us to predict that differences in plasticity outcomes in different studies are due to differences in parameters defining the calcium dynamics. The model provides a mechanistic understanding of how various stimulation protocols provoke specific synaptic changes through the dynamics of calcium concentration and thresholds implementing in simplified fashion protein signaling cascades, leading to long-term potentiation and long-term depression. The combination of biophysical realism and analytical tractability makes it the ideal candidate to study plasticity at the synapse, neuron, and network levels.},
author = {Graupner, M. and Brunel, N.},
doi = {10.1073/pnas.1109359109},
isbn = {0027842410916490},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {10},
pages = {3991--3996},
pmid = {22357758},
publisher = {National Acad Sciences},
title = {{Calcium-based plasticity model explains sensitivity of synaptic changes to spike pattern, rate, and dendritic location}},
volume = {109},
year = {2012}
}
@article{Harris2003,
author = {Harris, K D and Csicsvari, J and Hirase, H and Dragoi, G and Buzs{\'{a}}ki, G},
journal = {Nature},
number = {6948},
pages = {552--556},
title = {{Organization of cell assemblies in the hippocampus}},
volume = {424},
year = {2003}
}
@article{Kobayashi2019,
abstract = {State-of-the-art techniques allow researchers to record large numbers of spike trains in parallel for many hours. With enough such data, we should be able to infer the connectivity among neurons. Here we develop a method for reconstructing neuronal circuitry by applying a generalized linear model (GLM) to spike cross-correlations. Our method estimates connections between neurons in units of postsynaptic potentials and the amount of spike recordings needed to verify connections. The performance of inference is optimized by counting the estimation errors using synthetic data. This method is superior to other established methods in correctly estimating connectivity. By applying our method to rat hippocampal data, we show that the types of estimated connections match the results inferred from other physiological cues. Thus our method provides the means to build a circuit diagram from recorded spike trains, thereby providing a basis for elucidating the differences in information processing in different brain regions.},
author = {Kobayashi, Ryota and Kurita, Shuhei and Kurth, Anno and Kitano, Katsunori and Mizuseki, Kenji and Diesmann, Markus and Richmond, Barry J and Shinomoto, Shigeru},
doi = {10.1038/s41467-019-12225-2},
issn = {2041-1723},
journal = {Nature Communications},
number = {1},
pages = {4468},
title = {{Reconstructing neuronal circuitry from parallel spike trains}},
url = {https://doi.org/10.1038/s41467-019-12225-2},
volume = {10},
year = {2019}
}
@inproceedings{NIPS2014_4122cb13,
author = {Linderman, Scott and Stock, Christopher H and Adams, Ryan P},
booktitle = {Advances in Neural Information Processing Systems},
editor = {Ghahramani, Z and Welling, M and Cortes, C and Lawrence, N and Weinberger, K Q},
pages = {2330--2338},
publisher = {Curran Associates, Inc.},
title = {{A framework for studying synaptic plasticity with neural spike train data}},
url = {https://proceedings.neurips.cc/paper/2014/file/4122cb13c7a474c1976c9706ae36521d-Paper.pdf},
volume = {27},
year = {2014}
}
@article{Mantel1987,
abstract = {The functional connections between corticospinal neurones and motor units of the monkey's hand muscles were investigated by constructing cross-correlograms of activity recorded from pyramidal tract neurones and from single motor units in the contralateral thenar muscles during performance of a precision grip between thumb and index finger. Only those neurones which produced postspike facilitation of the surface-recorded electromyogram (EMG) of these muscles were selected for analysis. Positive correlations were observed for 11 15 selected neurones, and the form of the correlation was suggestive of monosynaptic action. Corticospinal cells which produced a correlation peak often did so with all concurrently-sampled motor units. {\textcopyright} 1987.},
author = {Mantel, G. W.H. and Lemon, R. N.},
doi = {10.1016/0304-3940(87)90617-3},
issn = {03043940},
journal = {Neuroscience Letters},
keywords = {Corticospinal neuron,Cross-correlation,Hand muscle,Monkey,Motor unit},
month = {jun},
number = {1},
pages = {113--118},
pmid = {3601210},
publisher = {Elsevier},
title = {{Cross-correlation reveals facilitation of single motor units in thenar muscles by single corticospinal neurones in the conscious monkey}},
volume = {77},
year = {1987}
}
@article{Okatan2005,
author = {Okatan, M and Wilson, M A and Brown, E N},
journal = {Neural Computation},
number = {9},
pages = {1927--1961},
publisher = {MIT Press},
title = {{Analyzing Functional Connectivity Using a Network Likelihood Model of Ensemble Neural Spiking Activity}},
volume = {17},
year = {2005}
}
@article{Paninski2004,
author = {Paninski, L},
journal = {Network: Computation in Neural Systems},
pages = {243--262},
title = {{Maximum likelihood estimation of cascade point-process neural encoding models}},
volume = {15},
year = {2004}
}
@misc{Paninski2010,
abstract = {State space methods have proven indispensable in neural data analysis. However, common methods for performing inference in state-space models with non-Gaussian observations rely on certain approximations which are not always accurate. Here we review direct optimization methods that avoid these approximations, but that nonetheless retain the computational efficiency of the approximate methods. We discuss a variety of examples, applying these direct optimization techniques to problems in spike train smoothing, stimulus decoding, parameter estimation, and inference of synaptic properties. Along the way, we point out connections to some related standard statistical methods, including spline smoothing and isotonic regression. Finally, we note that the computational methods reviewed here do not in fact depend on the state-space setting at all; instead, the key property we are exploiting involves the bandedness of certain matrices. We close by discussing some applications of this more general point of view, including Markov chain Monte Carlo methods for neural decoding and efficient estimation of spatially-varying firing rates. {\textcopyright} 2009 Springer Science+Business Media, LLC.},
author = {Paninski, Liam and Ahmadian, Yashar and Ferreira, Daniel Gil and Koyama, Shinsuke and {Rahnama Rad}, Kamiar and Vidne, Michael and Vogelstein, Joshua and Wu, Wei},
booktitle = {Journal of Computational Neuroscience},
doi = {10.1007/s10827-009-0179-x},
issn = {09295313},
keywords = {Hidden Markov model,Neural coding,State-space models,Tridiagonal matrix},
month = {aug},
number = {1-2},
pages = {107--126},
pmid = {19649698},
publisher = {Springer},
title = {{A new look at state-space models for neural data}},
url = {https://link.springer.com/article/10.1007/s10827-009-0179-x},
volume = {29},
year = {2010}
}
@article{Perkel1967,
abstract = {The statistical analysis of two simultaneously observed trains of neuronal spikes is described, using as a conceptual framework the theory of stochastic point processes. The first statistical question that arises is whether the observed trains are independent; statistical techniques for testing independence are developed around the notion that, under the null hypothesis, the times of spike occurrence in one train represent random instants in time with respect to the other. If the null hypothesis is rejected—if dependence is attributed to the trains—the problem then becomes that of characterizing the nature and source of the observed dependencies. Statistical signs of various classes of dependencies, including direct interaction and shared input, are discussed and illustrated through computer simulations of interacting neurons. The effects of nonstationarities on the statistical measures for simultaneous spike trains are also discussed. For two-train comparisons of irregularly discharging nerve cells, moderate nonstationarities are shown to have little effect on the detection of interactions. Combining repetitive stimulation and simultaneous recording of spike trains from two (or more) neurons yields additional clues as to possible modes of interaction among the monitored neurons; the theory presented is illustrated by an application to experimentally obtained data from auditory neurons. A companion paper covers the analysis of single spike trains. {\textcopyright} 1967, The Biophysical Society. All rights reserved.},
author = {Perkel, Donald H. and Gerstein, George L. and Moore, George P.},
doi = {10.1016/S0006-3495(67)86597-4},
issn = {00063495},
journal = {Biophysical Journal},
keywords = {Action Potentials*,Animals,Cats,Cochlear Nerve / physiology*,Computers,D H Perkel,Electric Stimulation,G L Gerstein,G P Moore,MEDLINE,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,PMC1368069,Probability*,PubMed Abstract,Statistics as Topic,Synaptic Transmission*,doi:10.1016/S0006-3495(67)86597-4,pmid:4292792},
number = {4},
pages = {419--440},
pmid = {4292792},
publisher = {Biophys J},
title = {{Neuronal Spike Trains and Stochastic Point Processes: II. Simultaneous Spike Trains}},
url = {https://pubmed.ncbi.nlm.nih.gov/4292792/},
volume = {7},
year = {1967}
}
@article{RAUCH1965,
annote = {doi: 10.2514/3.3166},
author = {Rauch, H E and Tung, F and Striebel, C T},
doi = {10.2514/3.3166},
issn = {0001-1452},
journal = {AIAA Journal},
month = {aug},
number = {8},
pages = {1445--1450},
publisher = {American Institute of Aeronautics and Astronautics},
title = {{Maximum likelihood estimates of linear dynamic systems}},
url = {https://doi.org/10.2514/3.3166},
volume = {3},
year = {1965}
}
@article{Ren2020,
abstract = {Detecting synaptic connections using large-scale extracellular spike recordings presents a statistical challenge. While previous methods often treat the detection of each putative connection as a separate hypothesis test, here we develop a modeling approach that infers synaptic connections while incorporating circuit properties learned from the whole network. We use an extension of the Generalized Linear Model framework to describe the cross-correlograms between pairs of neurons and separate correlograms into two parts: a slowly varying effect due to background fluctuations and a fast, transient effect due to the synapse. We then use the observations from all putative connections in the recording to estimate two network properties: the presynaptic neuron type (excitatory or inhibitory) and the relationship between synaptic latency and distance between neurons. Constraining the presynaptic neuron's type, synaptic latencies, and time constants improves synapse detection. In data from simulated networks, this model outperforms two previously developed synapse detection methods, especially on the weak connections. We also apply our model to in vitro multielectrode array recordings from mouse somatosensory cortex. Here our model automatically recovers plausible connections from hundreds of neurons, and the properties of the putative connections are largely consistent with previous research.},
annote = {doi: 10.1152/jn.00066.2020},
author = {Ren, Naixin and Ito, Shinya and Hafizi, Hadi and Beggs, John M and Stevenson, Ian H},
doi = {10.1152/jn.00066.2020},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
month = {sep},
publisher = {American Physiological Society},
title = {{Model-based detection of putative synaptic connections from spike recordings with latency and type constraints}},
url = {https://doi.org/10.1152/jn.00066.2020},
year = {2020}
}
@article{Smith2003,
abstract = {A widely used signal processing paradigm is the state-space model. The state-space model is defined by two equations: an observation equation that describes how the hidden state or latent process is observed and a state equation that defines the evolution of the process through time. Inspired by neurophysiology experiments in which neural spiking activity is induced by an implicit (latent) stimulus, we develop an algorithm to estimate a state-space model observed through point process measurements. We represent the latent process modulating the neural spiking activity as a gaussian autoregressive model driven by an external stimulus. Given the latent process, neural spiking activity is characterized as a general point process defined by its conditional intensity function. We develop an approximate expectation-maximization (EM) algorithm to estimate the unobservable state-space process, its parameters, and the parameters of the point process. The EM algorithm combines a point process recursive nonlinear filter algorithm, the fixed interval smoothing algorithm, and the state-space covariance algorithm to compute the complete data log likelihood efficiently. We use a Kolmogorov-Smirnov test based on the time-rescaling theorem to evaluate agreement between the model and point process data. We illustrate the model with two simulated data examples: an ensemble of Poisson neurons driven by a common stimulus and a single neuron whose conditional intensity function is approximated as a local Bernoulli process.},
author = {Smith, Anne C. and Brown, Emery N.},
doi = {10.1162/089976603765202622},
issn = {08997667},
journal = {Neural Computation},
month = {may},
number = {5},
pages = {965--991},
pmid = {12803953},
publisher = { MIT Press  238 Main St., Suite 500, Cambridge, MA 02142-1046 USA journals-info@mit.edu  },
title = {{Estimating a state-space model from point process observations}},
url = {https://www.mitpressjournals.org/doix/abs/10.1162/089976603765202622},
volume = {15},
year = {2003}
}
@article{Stevenson2018,
abstract = {Generalized linear models (GLMs) have a wide range of applications in systems neuroscience describing the encoding of stimulus and behavioral variables, as well as the dynamics of single neurons. However, in any given experiment, many variables that have an impact on neural activity are not observed or not modeled. Here we demonstrate, in both theory and practice, how these omitted variables can result in biased parameter estimates for the effects that are included. In three case studies, we estimate tuning functions for common experiments in motor cortex, hippocampus, and visual cortex. We find that including traditionally omitted variables changes estimates of the original parameters and that modulation originally attributed to one variable is reduced after new variables are included. In GLMs describing single-neuron dynamics, we then demonstrate how postspike history effects can also be biased by omitted variables. Here we find that omitted variable bias can lead to mistaken conclusions about the stability of single-neuron firing. Omitted variable bias can appear in any model with confounders?where omitted variables modulate neural activity and the effects of the omitted variables covary with the included effects. Understanding how and to what extent omitted variable bias affects parameter estimates is likely to be important for interpreting the parameters and predictions of many neural encoding models.},
annote = {doi: 10.1162/neco{\_}a{\_}01138},
author = {Stevenson, Ian H},
doi = {10.1162/neco_a_01138},
issn = {0899-7667},
journal = {Neural Computation},
month = {oct},
number = {12},
pages = {3227--3258},
publisher = {MIT Press},
title = {{Omitted Variable Bias in GLMs of Neural Spiking Activity}},
url = {https://doi.org/10.1162/neco{\_}a{\_}01138},
volume = {30},
year = {2018}
}
@inproceedings{Stevenson2011,
author = {Stevenson, Ian H. and Kording, K},
booktitle = {Advances in Neural Information Processing Systems},
editor = {Shawe-Taylor, J and Zemel, R S and Bartlett, P and Pereira, F C N and Weinberger, K Q},
isbn = {9781618395993},
title = {{Inferring spike-timing-dependent plasticity from spike train data}},
volume = {24},
year = {2011}
}
@article{Swadlow2001,
abstract = {Considerable effort has gone into understanding the mechanisms underlying high-frequency 'bursting' of thalamocortical impulses, their sensory information content and their involvement in perception. However, little is known about the influence of such impulses on their cortical targets. Here we follow bursting thalamic impulses to their terminus at the thalamocortical synapse of the awake rabbit, and examine their influence on a class of somatosensory cortical neurons. We show that thalamic bursts potently activate cortical circuits. Initial impulses of each burst have a greatly enhanced ability to elicit cortical action potentials, and later impulses in the burst further raise the probability of eliciting spikes. In some cases, multiple cortical spikes result from a single burst. Moreover, we show that the interval preceding each burst is crucial for generating the enhanced cortical response. The powerful activation of neocortex by thalamocortical bursts is fully consistent with an involvement of these impulses in perceptual/attentional processes.},
author = {Swadlow, Harvey A and Gusev, Alexander G},
doi = {10.1038/86054},
issn = {1546-1726},
journal = {Nature Neuroscience},
number = {4},
pages = {402--408},
title = {{The impact of 'bursting' thalamic impulses at a neocortical synapse}},
url = {https://doi.org/10.1038/86054},
volume = {4},
year = {2001}
}
@article{Truccolo2005,
author = {Truccolo, W and Eden, U T and Fellows, M R and Donoghue, J P and Brown, E N},
journal = {Journal of Neurophysiology},
number = {2},
pages = {1074--1089},
publisher = {Am Physiological Soc},
title = {{A Point Process Framework for Relating Neural Spiking Activity to Spiking History, Neural Ensemble, and Extrinsic Covariate Effects}},
volume = {93},
year = {2005}
}
@article{Usrey2000,
abstract = {We performed experiments in the cat geniculocortical pathway, in vivo, to examine how presynaptic spikes interact to influence the firing of postsynaptic targets. In particular, we asked (1) how do multiple spikes from a single presynaptic neuron interact to influence the firing of a postsynaptic target (homosynaptic interactions), (2) how do spikes from two different presynaptic neurons interact (heterosynaptic interactions), and (3) what is the time course of homosynaptic and heterosynaptic interactions? We found that both homosynaptic and heterosynaptic interactions increase the likelihood of driving a postsynaptic spike, although with different time courses. For two spikes traveling down a single geniculate axon, the second spike is more effective than the first for {\~{}}15 msec. For two spikes on separate axons, the interaction is faster ({\~{}}7 msec duration, {\~{}}2.5 msec time constant). Thus changes in firing rate are perhaps best relayed by homosynaptic interactions, whereas heterosynaptic interactions may help detect coincident spikes from different thalamic inputs.},
author = {Usrey, W. Martin and Alonso, Jose Manuel and Reid, R. Clay},
doi = {10.1523/jneurosci.20-14-05461.2000},
issn = {02706474},
journal = {Journal of Neuroscience},
keywords = {Area 17,Coincidence detection,Geniculocortical,Lateral geniculate nucleus,Thalamus},
month = {jul},
number = {14},
pages = {5461--5467},
pmid = {10884329},
publisher = {Society for Neuroscience},
title = {{Synaptic interactions between thalamic inputs to simple cells in cat visual cortex}},
url = {https://www.jneurosci.org/content/20/14/5461 https://www.jneurosci.org/content/20/14/5461.abstract},
volume = {20},
year = {2000}
}
@article{Volgushev2015,
abstract = {{\textcopyright} 2015 Volgushev et al. Accurately describing synaptic interactions between neurons and how interactions change over time are key challenges for systems neuroscience. Although intracellular electrophysiology is a powerful tool for studying synaptic integration and plasticity, it is limited by the small number of neurons that can be recorded simultaneously in vitro and by the technical difficulty of intracellular recording in vivo. One way around these difficulties may be to use large-scale extracellular recording of spike trains and apply statistical methods to model and infer functional connections between neurons. These techniques have the potential to reveal large-scale connectivity structure based on the spike timing alone. However, the interpretation of functional connectivity is often approximate, since only a small fraction of presynaptic inputs are typically observed. Here we use in vitro current injection in layer 2/3 pyramidal neurons to validate methods for inferring functional connectivity in a setting where input to the neuron is controlled. In experiments with partially-defined input, we inject a single simulated input with known amplitude on a background of fluctuating noise. In a fully-defined input paradigm, we then control the synaptic weights and timing of many simulated presynaptic neurons. By analyzing the firing of neurons in response to these artificial inputs, we ask 1) How does functional connectivity inferred from spikes relate to simulated synaptic input? and 2) What are the limitations of connectivity inference? We find that individual current-based synaptic inputs are detectable over a broad range of amplitudes and conditions. Detectability depends on input amplitude and output firing rate, and excitatory inputs are detected more readily than inhibitory. Moreover, as we model increasing numbers of presynaptic inputs, we are able to estimate connection strengths more accurately and detect the presence of connections more quickly. These results illustrate the possibilities and outline the limits of  inferring synaptic input from spikes.},
author = {Volgushev, M. and Ilin, V. and Stevenson, I.H.},
doi = {10.1371/journal.pcbi.1004167},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {3},
title = {{Identifying and Tracking Simulated Synaptic Inputs from Neuronal Firing: Insights from In Vitro Experiments}},
volume = {11},
year = {2015}
}
@article{Weber2017,
abstract = {A key problem in computational neuroscience is to find simple, tractable models that are nevertheless flexible enough to capture the response properties of real neurons. Here we examine the capabilities of recurrent point process models known as Poisson generalized linear models (GLMs). These models are defined by a set of linear filters and a point nonlinearity and are conditionally Poisson spiking. They have desirable statistical properties for fitting and have been widely used to analyze spike trains from electrophysiological recordings. However, the dynamical repertoire of GLMs has not been systematically compared to that of real neurons. Here we show that GLMs can reproduce a comprehensive suite of canonical neural response behaviors, including tonic and phasic spiking, bursting, spike rate adaptation, type I and type II excitation, and two forms of bistability. GLMs can also capture stimulus-dependent changes in spike timing precision and reliability that mimic those observed in real neurons, and ca...},
author = {Weber, Alison I. and Pillow, Jonathan W.},
doi = {10.1162/neco_a_01021},
issn = {0899-7667},
journal = {Neural Computation},
month = {dec},
number = {12},
pages = {3260--3289},
publisher = { MIT Press  One Rogers St., Cambridge, MA 02142-1209 USA journals-info@mit.edu  },
title = {{Capturing the Dynamical Repertoire of Single Neurons with Generalized Linear Models}},
volume = {29},
year = {2017}
}
@article{Zucker2002,
abstract = {Synaptic transmission is a dynamic process. Postsynaptic responses wax and wane as presynaptic activity evolves. This prominent characteristic of chemical synaptic transmission is a crucial determinant of the response properties of synapses and, in turn, of the stimulus properties selected by neural networks and of the patterns of activity generated by those networks. This review focuses on synaptic changes that result from prior activity in the synapse under study, and is restricted to short-term effects that last for at most a few minutes. Forms of synaptic enhancement, such as facilitation, augmentation, and post-tetanic potentiation, are usually attributed to effects of a residual elevation in presynaptic [Ca2+]i, acting on one or more molecular targets that appear to be distinct from the secretory trigger responsible for fast exocytosis and phasic release of transmitter to single action potentials. We discuss the evidence for this hypothesis, and the origins of the different kinetic phases of synaptic enhancement, as well as the interpretation of statistical changes in transmitter release and roles played by other factors such as alterations in presynaptic Ca2+ influx or postsynaptic levels of [Ca2+]i. Synaptic depression dominates enhancement at many synapses. Depression is usually attributed to depletion of some pool of readily releasable vesicles, and various forms of the depletion model are discussed. Depression can also arise from feedback activation of presynaptic receptors and from postsynaptic processes such as receptor desensitization. In addition, glial-neuronal interactions can contribute to short-term synaptic plasticity. Finally, we summarize the recent literature on putative molecular players in synaptic plasticity and the effects of genetic manipulations and other modulatory influences.},
author = {Zucker, Robert S. and Regehr, Wade G.},
doi = {10.1146/annurev.physiol.64.092501.114547},
issn = {0066-4278},
journal = {Annual Review of Physiology},
keywords = {Augmentation,Calcium,Depression,Facilitation,Post-tetanic potentiation,Synapse},
month = {mar},
number = {1},
pages = {355--405},
publisher = { Annual Reviews  4139 El Camino Way, P.O. Box 10139, Palo Alto, CA 94303-0139, USA  },
title = {{Short-Term Synaptic Plasticity}},
url = {http://www.annualreviews.org/doi/10.1146/annurev.physiol.64.092501.114547},
volume = {64},
year = {2002}
}
